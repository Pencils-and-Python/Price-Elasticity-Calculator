{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìà Elasticity Project: Model Summary\n",
    "\n",
    "This model focuses on **Price Elasticity of Demand (PED)** and its effect on total revenue. It allows users to explore how changes in price influence quantity demanded and overall sales performance.\n",
    "\n",
    "## ‚úÖ **Key Components:**\n",
    "\n",
    "1. **Price Elasticity of Demand (PED) Calculation**\n",
    "\n",
    "   The elasticity is calculated using the midpoint formula to provide stable and realistic elasticity estimates:\n",
    "\n",
    "   $$\n",
    "   E_d = \\frac{\\frac{Q_2 - Q_1}{(Q_2 + Q_1)/2}}{\\frac{P_2 - P_1}{(P_2 + P_1)/2}}\n",
    "   $$\n",
    "\n",
    "   Where:\n",
    "   - \\( Q_1 \\), \\( Q_2 \\) = Original and new quantity demanded.\n",
    "   - \\( P_1 \\), \\( P_2 \\) = Original and new price.\n",
    "\n",
    "2. **Elasticity Classification**\n",
    "\n",
    "   The model classifies elasticity as:\n",
    "   - **Elastic** if \\( E_d > 1 \\)\n",
    "   - **Inelastic** if \\( E_d < 1 \\)\n",
    "   - **Unitary Elastic** if \\( E_d = 1 \\)\n",
    "\n",
    "3. **Revenue Impact Calculation**\n",
    "\n",
    "   We calculate **Total Revenue (TR)** before and after the price change:\n",
    "\n",
    "   $$\n",
    "   TR_1 = P_1 \\times Q_1\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   TR_2 = P_2 \\times Q_2\n",
    "   $$\n",
    "\n",
    "   The **change in revenue** is expressed as:\n",
    "\n",
    "   $$\n",
    "   \\Delta TR = TR_2 - TR_1\n",
    "   $$\n",
    "\n",
    "4. **Visualizations**\n",
    "\n",
    "   - **Demand Curve Plot:**\n",
    "     Shows the demand curve shifting based on user input.\n",
    "   - **Revenue Comparison:**\n",
    "     Displays side-by-side revenue before and after the price change.\n",
    "\n",
    "5. **User Inputs (via Sliders):**\n",
    "   - Initial price (\\( P_1 \\))\n",
    "   - Initial quantity (\\( Q_1 \\))\n",
    "   - % change in price (\\( \\%\\Delta P \\))\n",
    "\n",
    "6. **Output:**\n",
    "   - New price & quantity estimates.\n",
    "   - Elasticity classification (with interpretation).\n",
    "   - Revenue before & after (with impact summary).\n",
    "   - Interactive graph updates in real-time.\n"
   ],
   "id": "2fe5897a6d996bdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:01:11.198358Z",
     "start_time": "2025-05-08T06:01:11.193126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ],
   "id": "5b1ab86a2f59194d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:42.204075Z",
     "start_time": "2025-05-08T03:49:41.708335Z"
    }
   },
   "source": "processed_data = pd.read_csv('../data/processed/processed_data.csv')",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ‚úÖ Check data is clean",
   "id": "67c138ebdd69bed9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:42.316475Z",
     "start_time": "2025-05-08T03:49:42.231649Z"
    }
   },
   "cell_type": "code",
   "source": "processed_data.info()",
   "id": "779496c7a7baea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 843482 entries, 0 to 843481\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Date           843482 non-null  object\n",
      " 1   Store          843482 non-null  int64 \n",
      " 2   DayOfWeek      843482 non-null  int64 \n",
      " 3   Sales          843482 non-null  int64 \n",
      " 4   Customers      843482 non-null  int64 \n",
      " 5   Open           843482 non-null  int64 \n",
      " 6   Promo          843482 non-null  int64 \n",
      " 7   StateHoliday   843482 non-null  int64 \n",
      " 8   SchoolHoliday  843482 non-null  int64 \n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 57.9+ MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:42.407743Z",
     "start_time": "2025-05-08T03:49:42.376092Z"
    }
   },
   "cell_type": "code",
   "source": "processed_data.head()\n",
   "id": "808d072d5c26bc5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date  Store  DayOfWeek  Sales  Customers  Open  Promo  StateHoliday  \\\n",
       "0  2015-07-31      1          5   5263        555     1      1             0   \n",
       "1  2015-07-31      2          5   6064        625     1      1             0   \n",
       "2  2015-07-31      3          5   8314        821     1      1             0   \n",
       "3  2015-07-31      4          5  13995       1498     1      1             0   \n",
       "4  2015-07-31      5          5   4822        559     1      1             0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üî• First elasticity-style insight: Promo effect\n",
    "- We can directly model the effect of Promo (binary: 0/1) on Sales. This tells you:\n",
    "\n",
    "- How much more (or less) you sell when running a promo vs. not running one.\n",
    "\n",
    "- Even a simple OLS regression can give you:\n",
    "\n",
    "- The coefficient for Promo ‚Üí this acts like a proxy elasticity for how responsive sales are to promotions."
   ],
   "id": "43da1635d01238c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üí° Let‚Äôs draft the steps:\n",
   "id": "9d2d9de90ea61050"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1Ô∏è‚É£ Convert Date as before:",
   "id": "d488e054e6fd0eb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:42.866015Z",
     "start_time": "2025-05-08T03:49:42.591277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_data['Date'] = pd.to_datetime(processed_data['Date'])\n",
    "processed_data['Month'] = processed_data['Date'].dt.month\n",
    "processed_data['Year'] = processed_data['Date'].dt.year\n",
    "processed_data['WeekOfYear'] = processed_data['Date'].dt.isocalendar().week\n"
   ],
   "id": "1c29a9af922ab980",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2Ô∏è‚É£ Filter to open stores only (because closed = 0 sales):",
   "id": "e7e5c006d7ea0936"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:42.993465Z",
     "start_time": "2025-05-08T03:49:42.952839Z"
    }
   },
   "cell_type": "code",
   "source": "data_open = processed_data[processed_data['Open'] == 1]\n",
   "id": "a0f89d469e858fa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3Ô∏è‚É£ Set up features & target:",
   "id": "8bfae0591de9f7c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:43.566128Z",
     "start_time": "2025-05-08T03:49:43.544415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = ['Promo', 'StateHoliday', 'SchoolHoliday', 'DayOfWeek', 'Month', 'Year']\n",
    "X = data_open[features]\n",
    "y = data_open['Sales']\n"
   ],
   "id": "d2fe8893ce740908",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4Ô∏è‚É£ Linear regression:",
   "id": "39702155669f8247"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:44.206289Z",
     "start_time": "2025-05-08T03:49:43.740066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train R^2:\", lr.score(X_train, y_train))\n",
    "print(\"Test R^2:\", lr.score(X_test, y_test))\n"
   ],
   "id": "bdb849d35fd7a28c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.1502372392327186\n",
      "Test R^2: 0.1487795746920464\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5Ô∏è‚É£ Elasticity-like insight: Promo effect\n",
    "After training, check the coefficients:"
   ],
   "id": "6893c1a91a818013"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:44.358107Z",
     "start_time": "2025-05-08T03:49:44.331015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coef_table = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr.coef_\n",
    "})\n",
    "print(coef_table)\n"
   ],
   "id": "9b3eacabd77b2d86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature   Coefficient\n",
      "0          Promo  2.158871e+03\n",
      "1   StateHoliday  4.831691e-13\n",
      "2  SchoolHoliday  7.052238e+01\n",
      "3      DayOfWeek -1.367336e+02\n",
      "4          Month  8.163864e+01\n",
      "5           Year  2.024603e+02\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîç Analysis of the model",
   "id": "acaabefa6c0ca0b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üü¢ Promo: +2158.87\n",
    "üí• BOOM‚Äîthis is your headline stat.\n",
    "\n",
    "‚úÖ On average, when a promo is running, sales increase by about 2,159 units compared to days when there‚Äôs no promo.\n",
    "\n",
    "üìà This is your \"promotion elasticity proxy\"‚Äîwhile it‚Äôs not a percentage change (since we don‚Äôt have price), it tells you how sensitive sales are to the presence of a promotion.\n",
    "\n"
   ],
   "id": "8b6557d6782da2a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üü† StateHoliday: ~ 0 (4.8e-13)\n",
    "That‚Äôs super tiny‚Äîbasically no effect.\n",
    "\n",
    "This tells us:\n",
    "\n",
    "üèñÔ∏è Whether it‚Äôs a state holiday or not doesn‚Äôt seem to impact sales much in your data.\n",
    "\n",
    "Do we know if this column had real variation (were there holidays at all?), or was it sparse? Worth checking with:"
   ],
   "id": "3d88feba0022768"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:44.555040Z",
     "start_time": "2025-05-08T03:49:44.533249Z"
    }
   },
   "cell_type": "code",
   "source": "print(processed_data['StateHoliday'].value_counts())\n",
   "id": "788898f19434db75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateHoliday\n",
      "0    843482\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## This tells us:\n",
    "\n",
    "- ‚úÖ 100% of your data points (843,482 rows) have StateHoliday = 0.\n",
    "- ‚ùå No actual state holidays are present."
   ],
   "id": "7c0d612afa732da0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üí° Why did the model give us that tiny coefficient (~4.8e-13)?\n",
    "- Because the StateHoliday feature is constant‚Äîit never changes. That means it's giving the model no real signal at all.\n",
    "\n",
    "- In linear regression, when a feature has no variation, it can‚Äôt actually contribute meaningfully to prediction. The regression still assigns it a tiny (basically zero) coefficient, but it‚Äôs doing nothing."
   ],
   "id": "6b65425732795225"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ‚úÖ Next Steps?\n",
    "- Remove StateHoliday from the feature list going forward because:\n",
    "    - It‚Äôs useless here (no variation = no predictive power).\n",
    "    - It might even slightly slow down or complicate future models (especially tree-based ones that don‚Äôt handle constant features well)."
   ],
   "id": "5b69bf7c49a99ff6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üü° SchoolHoliday: +70.5\n",
    "This one's interesting:\n",
    "\n",
    "- When there‚Äôs a school holiday, sales increase by ~71 units on average.\n",
    "- Not a massive effect, but it‚Äôs positive.\n",
    "\n",
    "‚úÖ This makes intuitive sense‚Äîfamilies might shop more when kids are out of school.\n",
    "\n",
    "### üîµ DayOfWeek: -136.7\n",
    "This one tells us that as the day of the week increases (likely Monday=1 up to Sunday=7):\n",
    "\n",
    "- Sales drop about 137 units per day going later in the week.\n",
    "- It‚Äôs linear here, so it might not fully capture patterns like weekend spikes‚Äîthis could be better handled later with dummy variables (categoricals).\n",
    "\n",
    "### üü£ Month: +81.6\n",
    "Each later month in the year is associated with ~82 units more in sales.\n",
    "\n",
    "- This may reflect seasonality trends (e.g., Q4 increases), but it‚Äôs a pretty small per-month bump.\n",
    "\n",
    "### üü§ Year: +202.5\n",
    "Each year forward (like from 2022 to 2023) is associated with ~202 extra sales units.\n",
    "\n",
    "- This suggests an upward trend year over year (maybe business growth, inflation, or other market factors)."
   ],
   "id": "b83260856033c011"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üö¶ What‚Äôs the Big Takeaway?\n",
    "\n",
    "| üìä **Feature**      | üí• **Interpretation**                                                                                      |\n",
    "|---------------------|----------------------------------------------------------------------------------------------------------|\n",
    "| **Promo**           | üî• **Major impact: +2159 sales boost.** This is your *main elasticity-like driver.*                       |\n",
    "| **StateHoliday**    | üí§ **No real effect.**                                                                                   |\n",
    "| **SchoolHoliday**   | üëç Small positive bump (~71 units).                                                                      |\n",
    "| **DayOfWeek**       | üìâ Sales **decline by ~137 units** later in the week (might hint at a weekend lull‚Äîworth deeper analysis). |\n",
    "| **Month**           | üìà Slight positive trend across months (~82 units increase per month).                                    |\n",
    "| **Year**            | üöÄ Solid +200 unit boost per year‚Äîsuggests business growth or other long-term upward trend.               |\n"
   ],
   "id": "af60064cfe7bbdab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note:** The `StateHoliday` feature was removed from further modeling because the dataset contains no actual state holidays (100% of rows have `StateHoliday = 0`), making it a constant feature with no predictive value.\n",
   "id": "9e9d7f33a4203668"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:44.774061Z",
     "start_time": "2025-05-08T03:49:44.765655Z"
    }
   },
   "cell_type": "code",
   "source": "features = ['Promo', 'SchoolHoliday', 'DayOfWeek', 'Month', 'Year']\n",
   "id": "3bdff098cf8719fb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2Ô∏è‚É£ üîÑ Re-split your data:\n",
    "Let‚Äôs keep things clean:"
   ],
   "id": "e7885517097a06c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:45.098763Z",
     "start_time": "2025-05-08T03:49:44.872099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data_open[features]\n",
    "y = data_open['Sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ],
   "id": "d715eceba70f6bd5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3Ô∏è‚É£ üöÄ Refit the model:",
   "id": "e16b4a16535cffdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:45.565454Z",
     "start_time": "2025-05-08T03:49:45.174110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train R^2:\", lr.score(X_train, y_train))\n",
    "print(\"Test R^2:\", lr.score(X_test, y_test))\n"
   ],
   "id": "504bd9878d52a553",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.15023723923271926\n",
      "Test R^2: 0.14877957469204728\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4Ô∏è‚É£ üßê Get the updated coefficients:",
   "id": "a65652d9e15d9f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:45.710077Z",
     "start_time": "2025-05-08T03:49:45.698830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coef_table = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr.coef_\n",
    "})\n",
    "print(coef_table)\n"
   ],
   "id": "bffa394952d6bb1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Coefficient\n",
      "0          Promo  2158.870979\n",
      "1  SchoolHoliday    70.522376\n",
      "2      DayOfWeek  -136.733631\n",
      "3          Month    81.638638\n",
      "4           Year   202.460311\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ‚úÖ What are the coefficents telling us?",
   "id": "289ea8cd529d2af9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| **Feature**       | **Coefficient** | **What it means**                                                                                           |\n",
    "|-------------------|-----------------|------------------------------------------------------------------------------------------------------------|\n",
    "| **Promo**         | 2158.87         | ‚ûî When `Promo` changes from 0 ‚Üí 1 (no promo ‚Üí promo), **sales increase by ~2159 units.**                    |\n",
    "| **SchoolHoliday** | 70.52           | ‚ûî When `SchoolHoliday` changes from 0 ‚Üí 1, **sales increase by ~71 units.**                                 |\n",
    "| **DayOfWeek**     | -136.73         | ‚ûî For each *increment* in `DayOfWeek` (e.g., Monday=1 ‚Üí Tuesday=2), **sales decrease by ~137 units.**       |\n",
    "| **Month**         | 81.64           | ‚ûî For each *increment* in `Month` (e.g., January=1 ‚Üí February=2), **sales increase by ~82 units.**          |\n",
    "| **Year**          | 202.46          | ‚ûî For each *increment* in `Year` (e.g., 2023 ‚Üí 2024), **sales increase by ~202 units.**                     |\n"
   ],
   "id": "632438b568a5c861"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÑ Model Update: Removed `StateHoliday`\n",
    "\n",
    "We re-ran the model after removing the `StateHoliday` feature (constant = 0). The updated model shows:\n",
    "\n",
    "- ‚úÖ Similar `Promo` effect (~ +2150 units).\n",
    "- ‚úÖ Slight refinement in other coefficients.\n",
    "- ‚úÖ Model performance remained stable, confirming `StateHoliday` had no predictive value.\n"
   ],
   "id": "24e4fa99e149a872"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:45.906958Z",
     "start_time": "2025-05-08T03:49:45.822168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train R^2:\", lr.score(X_train, y_train))\n",
    "print(\"Test R^2:\", lr.score(X_test, y_test))\n"
   ],
   "id": "bf4cbe66a3cac19f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.15023723923271926\n",
      "Test R^2: 0.14877957469204728\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Model Performance:**\n",
    "\n",
    "- **Train R¬≤:** 0.15\n",
    "- **Test R¬≤:** 0.15\n",
    "\n",
    "This indicates the model explains ~15% of the variance in sales. While this is relatively low, it reflects the noisy nature of sales data and the limited feature set (no price data, no detailed store/product information). The model successfully captures general patterns (e.g., the strong positive effect of promotions) but is not suitable for high-precision forecasting in its current form.\n",
    "\n",
    "#### **Next steps:**\n",
    "- Introduce categorical encoding for `DayOfWeek` and `Month`.\n",
    "- Add `Store` as a feature.\n",
    "- Explore non-linear models (e.g., RandomForest).\n",
    "- Investigate feature interactions (e.g., `Promo * DayOfWeek`).\n"
   ],
   "id": "3f92ffd51d867c18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check to see how many stores are included in the store data",
   "id": "73efb187908b2393"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:46.089322Z",
     "start_time": "2025-05-08T03:49:46.052352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(data_open['Store'].value_counts())\n",
    "print(data_open['Store'].nunique())\n"
   ],
   "id": "9086279e3c17c73c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store\n",
      "562    918\n",
      "85     918\n",
      "423    918\n",
      "262    918\n",
      "682    918\n",
      "      ... \n",
      "909    607\n",
      "100    606\n",
      "744    605\n",
      "348    597\n",
      "644    592\n",
      "Name: count, Length: 1115, dtype: int64\n",
      "1115\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The data shows there are 1,115 unique store IDs",
   "id": "f87b68cd0adda320"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why Move from Linear Regression to RandomForest?\n",
    "\n",
    "The initial linear regression model provided useful directional insights but yielded low explanatory power (R¬≤ ~0.15). This is expected because linear regression assumes purely linear relationships between features and sales. However, real-world retail sales are influenced by complex, non-linear patterns‚Äîsuch as store-specific behavior, varying promo effectiveness, and seasonal effects.\n",
    "\n",
    "Key reasons for adopting RandomForest:\n",
    "\n",
    "- **Non-linear modeling:** RandomForest captures complex, non-linear relationships automatically, without requiring manual feature engineering (e.g., interaction terms between Promo and Store).\n",
    "- **Better handling of categorical variables:** While linear regression requires one-hot encoding (adding 1,100+ dummy variables for `Store`), RandomForest efficiently handles categorical labels through simple label encoding.\n",
    "- **Automatic interaction learning:** RandomForest naturally identifies important interactions, such as certain stores being more sensitive to promotions on specific days.\n",
    "- **Improved predictive power:** Tree-based models typically yield higher R¬≤ in noisy retail datasets, offering more accurate predictions even with the same data.\n",
    "\n",
    "For these reasons, RandomForest was selected as the next modeling step to improve performance and capture deeper patterns in the sales data.\n"
   ],
   "id": "ce766963f7813ddb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìù Feature Engineering and Model Improvement Plan\n",
    "**Background:**<br>\n",
    "Our initial linear regression model achieved an R¬≤ of ~0.15, indicating poor explanatory power. This low score suggested that key sources of variance were missing from the model or that linear assumptions were too restrictive.\n",
    "\n",
    "**To address this, we decided to:**\n",
    "\n",
    "- Introduce additional predictive features\n",
    "\n",
    "- Move from a linear model to a non-linear model (Random Forest Regressor) to capture complex interactions."
   ],
   "id": "95f1879827f702f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Why add Store as a feature?\n",
    "- Each store likely has its own baseline sales patterns due to:\n",
    "- Location differences\n",
    "- Customer demographics\n",
    "- Local promotions\n",
    "- Competition\n",
    "üëâ Therefore, ignoring the Store variable omits a major source of variance in sales.\n",
    "\n",
    "*However:*\n",
    "- Store is a categorical variable with 1,115 unique values\n",
    "- Using one-hot encoding would add 1,115 new columns ‚Üí inefficient and risks overfitting\n",
    "- Tree-based models like Random Forest cannot handle string categories natively"
   ],
   "id": "d625fad27a53b0ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chosen Encoding: Target (Mean) Encoding\n",
    "We will encode Store by replacing each store ID with the average sales for that store in the training data.\n",
    "\n",
    "#### ‚úÖ Advantages:\n",
    "- Captures store-specific sales level\n",
    "- Keeps dimensionality low (single numeric feature)\n",
    "- Easy interpretation\n",
    "- Compatible with tree-based models\n",
    "\n",
    "#### ‚ö†Ô∏è Risk:\n",
    "- Data leakage: using target values to encode the same rows can cause overfitting\n",
    "\n",
    "**To mitigate leakage:**\n",
    "- Ideally, we would calculate mean sales only on the training fold during cross-validation\n",
    "- ‚úÖ Avoid data leakage from target encoding\n",
    "- ‚úÖ Preserve an unbiased validation/test set\n",
    "\n",
    "**The solution is:**\n",
    "- ‚Üí Use out-of-fold mean encoding during training\n",
    "- ‚Üí Or at minimum, calculate store means only on the training set and apply those mappings to the test set.\n",
    "\n",
    "#### üìê Why is this necessary?\n",
    "If we calculate store means on all data:\n",
    "- The encoding would ‚Äúpeek‚Äù at test data sales\n",
    "- Random Forest would be fitting on target information baked into features\n",
    "- Validation metrics would be overly optimistic"
   ],
   "id": "ce50c54fe63bfd43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìù Approach (no leakage):\n",
    "We split data before encoding:"
   ],
   "id": "1b50dde17d01ead9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:46.437099Z",
     "start_time": "2025-05-08T03:49:46.161405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split BEFORE encoding\n",
    "train_data, test_data = train_test_split(data_open, test_size=0.2, random_state=42)\n",
    "\n",
    "# calculate store means only on training set\n",
    "store_means = train_data.groupby('Store')['Sales'].mean()\n",
    "\n",
    "# map means to both train and test\n",
    "train_data['StoreEncoded'] = train_data['Store'].map(store_means)\n",
    "test_data['StoreEncoded'] = test_data['Store'].map(store_means)\n",
    "\n",
    "# for stores in test not seen in train ‚Üí fill with global mean\n",
    "global_mean = train_data['Sales'].mean()\n",
    "test_data['StoreEncoded'] = test_data['StoreEncoded'].fillna(global_mean)\n"
   ],
   "id": "a766bec9b81c9309",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation:\n",
    "- We split the data into train and test sets before encoding.\n",
    "- We calculate the store means on the training set and apply them to both train and test sets.\n",
    "- If a store is not present in the training set, we fill it with the global mean.\n",
    "- üëâ The random_state parameter controls the random number generator that shuffles your data before splitting it.\n",
    "    - If you don‚Äôt specify random_state, every time you run the code, you‚Äôd get a different split of train and test data.\n",
    "    - But by setting random_state=42 (or any number), you‚Äôre telling Python:\n",
    "        - \"*Hey, I want the split to be random‚Äîbut I want it to be the same random split every time I run this code.*\"\n",
    "    - ‚úÖ This is key for reproducibility:\n",
    "        - You‚Äôll get the exact same train/test sets every time you run the script.\n",
    "        - Someone else running your code (with the same random_state) will get the same results.\n",
    "    - üßê Why the number 42?\n",
    "        - The number 42 is just a popular in-joke from The Hitchhiker‚Äôs Guide to the Galaxy, where 42 is famously \"the answer to life, the universe, and everything.\"\n",
    "        - It could be any integer:"
   ],
   "id": "43ccd559f2c11a30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ‚úÖ Now we‚Äôre clean:\n",
    "\n",
    "- StoreEncoded in train is based only on train sales\n",
    "- StoreEncoded in test does not ‚Äúpeek‚Äù at its own target\n",
    "- Unseen stores ‚Üí fallback to global mean"
   ],
   "id": "4348699e46f3bdf4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üö® Avoiding Target Leakage in Store Encoding\n",
    "Target (mean) encoding introduces risk of data leakage when the target variable is used to encode both training and validation/test rows.\n",
    "\n",
    "üëâ Therefore, we calculate Store mean sales only on the training set and map those values to the test set.\n",
    "\n",
    "If a store in the test set wasn‚Äôt seen in training, we fill it with the global mean sales from the training set."
   ],
   "id": "4dc26822eb14eeb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üö¶ Quick pre-modeling readiness checklist:\n",
    "‚úÖ 1. No missing values in features you‚Äôre feeding to the model?<br>\n",
    "‚Üí       - Make sure no features (columns) still have NaNs or missing values.<br>\n",
    "‚Üí       - You already filled StoreEncoded for test data‚Äîbut check other columns too.<br>\n",
    "        - üìù If you have missing values elsewhere, you might need to impute (mean/median) or drop those rows/columns."
   ],
   "id": "1ccec4ff385f4104"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:46.511029Z",
     "start_time": "2025-05-08T03:49:46.495570Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_data.isnull().sum())\n",
   "id": "13e33089d74d5988",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0\n",
      "Store            0\n",
      "DayOfWeek        0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "Month            0\n",
      "Year             0\n",
      "WeekOfYear       0\n",
      "StoreEncoded     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:49:46.600899Z",
     "start_time": "2025-05-08T03:49:46.596756Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "171d00cd9524348c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "‚úÖ 2. All features numeric?\n",
    "\n",
    "- Random Forests can‚Äôt handle raw categorical data ‚Üí so check if any other columns are still categorical (like strings or objects).\n",
    "- If any features are object or category types, you‚Äôll need to encode them (one-hot encoding or another target encoding)."
   ],
   "id": "b24b498e8093f95e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T03:57:42.628602Z",
     "start_time": "2025-05-08T03:57:42.619017Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_data.dtypes)\n",
   "id": "b1a0b7764352cfe7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             datetime64[ns]\n",
      "Store                     int64\n",
      "DayOfWeek                 int64\n",
      "Sales                     int64\n",
      "Customers                 int64\n",
      "Open                      int64\n",
      "Promo                     int64\n",
      "StateHoliday              int64\n",
      "SchoolHoliday             int64\n",
      "Month                     int32\n",
      "Year                      int32\n",
      "WeekOfYear               UInt32\n",
      "StoreEncoded            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Results\n",
    "- Date has datetime64 dtype which cannot be used in modeling\n",
    "- Date should either be transformed or dropped"
   ],
   "id": "f583f45f141153fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Random Forest can‚Äôt handle datetime columns directly. You‚Äôve already extracted:\n",
    "\n",
    "‚úÖ Month<br>\n",
    "‚úÖ Year<br>\n",
    "‚úÖ WeekOfYear<br>\n",
    "‚úÖ DayOfWeek<br>\n",
    "\n",
    "üéØ The data has effectively already decomposed Date into its useful features.\n",
    "\n",
    "‚û°Ô∏è Therefore ‚Üí \"Date\" can safely drop Date for modeling:"
   ],
   "id": "31f429051c78b6d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "‚úÖ 3. Do you have your X and y separated?\n",
    "\n",
    "Need to define your features (X) and target (y):\n",
    "- ‚ö†Ô∏è If test set doesn‚Äôt have Sales yet (because you‚Äôre predicting), then you won‚Äôt have y_test."
   ],
   "id": "ea375f608ebb7eab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T05:25:57.641122Z",
     "start_time": "2025-05-08T05:25:57.607594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train_data.drop(['Sales', 'Date', 'Store'], axis=1)\n",
    "y_train = train_data['Sales']\n",
    "\n",
    "X_test = test_data.drop(['Sales', 'Date', 'Store'], axis=1)  # drop same cols\n",
    "y_test = test_data['Sales']  # only if Sales exists in test set\n"
   ],
   "id": "1e8e8232a99b8df6",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "‚úÖ 4. Scaling/normalization:\n",
    "\n",
    "Good news: Random Forest doesn‚Äôt require scaling or normalization.\n",
    "\n",
    "‚úîÔ∏è You can skip StandardScaler or MinMaxScaler ‚Üí that‚Äôs a win."
   ],
   "id": "84656c2026baeb17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "‚úÖ 5. Any weird outliers or illogical values?\n",
    "\n",
    "This step‚Äôs optional, but sometimes useful ‚Üí a quick histogram or describe() check to see if there are crazy extreme values that might throw off the model."
   ],
   "id": "5c21b5ac6007e50b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T05:40:51.052785Z",
     "start_time": "2025-05-08T05:40:51.047739Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_train.shape)\n",
   "id": "25b0564f828b0051",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(674785, 10)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T05:54:46.216566Z",
     "start_time": "2025-05-08T05:51:20.897481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# instantiate the model\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "# for testing\n",
    "rf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predict = rf.predict(X_test)\n",
    "\n",
    "# optionally evaluate (if y_test is known)\n",
    "\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "print(f'MSE: {mse:.2f}')\n"
   ],
   "id": "2decdb3a9e43c622",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 401733.90\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:01:31.275997Z",
     "start_time": "2025-05-08T06:01:31.252474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# calculate metrics\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "r2 = r2_score(y_test, predict)\n",
    "\n",
    "# print results\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.2f}\")\n",
    "print(f\"R^2: {r2:.4f}\")"
   ],
   "id": "3ee14ef27ccdd92a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 401733.90\n",
      "RMSE: 633.82\n",
      "R^2: 0.9582\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T05:51:04.703953Z",
     "start_time": "2025-05-08T05:50:28.691771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# instantiate the model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "print(\"Starting fit...\")\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Fit complete!\")\n",
    "\n",
    "print(\"Starting predict...\")\n",
    "predict = rf.predict(X_test)\n",
    "print(\"Prediction complete!\")\n",
    "\n",
    "print(\"Calculating MSE...\")\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "print(f\"MSE: {mse:.2f}\")\n"
   ],
   "id": "b291fc95640fb338",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fit...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m rf = RandomForestRegressor(random_state=\u001B[32m42\u001B[39m)\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mStarting fit...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[43mrf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFit complete!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mStarting predict...\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:487\u001B[39m, in \u001B[36mBaseForest.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    476\u001B[39m trees = [\n\u001B[32m    477\u001B[39m     \u001B[38;5;28mself\u001B[39m._make_estimator(append=\u001B[38;5;28;01mFalse\u001B[39;00m, random_state=random_state)\n\u001B[32m    478\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[32m    479\u001B[39m ]\n\u001B[32m    481\u001B[39m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[32m    482\u001B[39m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[32m    483\u001B[39m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[32m    484\u001B[39m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[32m    485\u001B[39m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[32m    486\u001B[39m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m487\u001B[39m trees = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mthreads\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    502\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    503\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    504\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    505\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    506\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    508\u001B[39m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[32m    509\u001B[39m \u001B[38;5;28mself\u001B[39m.estimators_.extend(trees)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/joblib/parallel.py:1985\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1983\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1984\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1985\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1987\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1988\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1989\u001B[39m \u001B[38;5;66;03m# reused, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1990\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1991\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1992\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/joblib/parallel.py:1913\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1911\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1912\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1913\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1914\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1915\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    137\u001B[39m     config = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:189\u001B[39m, in \u001B[36m_parallel_build_trees\u001B[39m\u001B[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001B[39m\n\u001B[32m    186\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m class_weight == \u001B[33m\"\u001B[39m\u001B[33mbalanced_subsample\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    187\u001B[39m         curr_sample_weight *= compute_sample_weight(\u001B[33m\"\u001B[39m\u001B[33mbalanced\u001B[39m\u001B[33m\"\u001B[39m, y, indices=indices)\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m     \u001B[43mtree\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    190\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurr_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    196\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    197\u001B[39m     tree._fit(\n\u001B[32m    198\u001B[39m         X,\n\u001B[32m    199\u001B[39m         y,\n\u001B[32m   (...)\u001B[39m\u001B[32m    202\u001B[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001B[32m    203\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/elasticity_risk_exposure/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001B[39m, in \u001B[36mBaseDecisionTree._fit\u001B[39m\u001B[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[39m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    462\u001B[39m     builder = BestFirstTreeBuilder(\n\u001B[32m    463\u001B[39m         splitter,\n\u001B[32m    464\u001B[39m         min_samples_split,\n\u001B[32m   (...)\u001B[39m\u001B[32m    469\u001B[39m         \u001B[38;5;28mself\u001B[39m.min_impurity_decrease,\n\u001B[32m    470\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m \u001B[43mbuilder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    475\u001B[39m     \u001B[38;5;28mself\u001B[39m.n_classes_ = \u001B[38;5;28mself\u001B[39m.n_classes_[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "392359ceccf9d423"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
